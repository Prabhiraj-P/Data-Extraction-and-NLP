{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Data Extraction and NLP"
      ],
      "metadata": {
        "id": "ef5LrCSCyHQt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Bxv8si8Wx7Y1"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#url\n",
        "url=\"https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/\"\n",
        "response=requests.get(url)"
      ],
      "metadata": {
        "id": "ZltjhHjyy0vh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup=BeautifulSoup(response.content,'html.parser')\n",
        "main_div=soup.find_all('div',{ 'class':\"tdb-block-inner td-fix-index\"})\n",
        "text2=soup.find_all('p')\n",
        "check=False\n",
        "main_text=[]\n",
        "for div in text2:\n",
        " repos=div.text.strip()\n",
        " if repos==\"Introduction\":\n",
        "   check=True\n",
        " if repos==\"Contact us: hello@blackcoffer.com\":\n",
        "   check=False\n",
        " if check:\n",
        "   main_text.append(repos)\n",
        "\n",
        "main_text.remove(\"Introduction\")\n",
        " "
      ],
      "metadata": {
        "id": "V6dwBfYSzVPX"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_text[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "omtbuZwzzzBB",
        "outputId": "5619f07a-528e-420f-c212-15389b0ff677"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'IBM Watson, a sophisticated AI that works on cloud computing and natural language processing, has prominently contributed to the healthcare sector on a global level. Being a conversational AI, since 2013, Watson has helped in recommending treatments to patients suffering from cancer to ensure that they get the best treatment at optimum costs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "code to read positive and negative words"
      ],
      "metadata": {
        "id": "kl35bGufGg7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive_fname='/content/positive-words.txt'\n",
        "negative_fname='/content/negative-words.txt'"
      ],
      "metadata": {
        "id": "QJdspAAmGoyx"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import remove\n",
        "positive=[]\n",
        "negative=[]\n",
        "with open(positive_fname,mode='r') as file:\n",
        "  positive_words=file.readlines()\n",
        "\n",
        "for word in positive_words:\n",
        "  positive.append(word[:len(word)-1])\n",
        "\n",
        "with open(negative_fname,mode='r',encoding='ISO-8859-1') as file:\n",
        "  negative_words=file.readlines()\n",
        "\n",
        "for word in negative_words:\n",
        "  negative.append(word[:len(word)-1])\n",
        "\n"
      ],
      "metadata": {
        "id": "cS1D4pPjGy6_"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "personal_pronouns = ['i', 'me', 'my', 'mine', 'you', 'your', 'yours', 'he', 'him', 'his', 'she', 'her', 'hers', 'it', 'its', 'we', 'us', 'our', 'ours', 'they', 'them', 'their', 'theirs']"
      ],
      "metadata": {
        "id": "7m244YhcEB54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parameter"
      ],
      "metadata": {
        "id": "UoR3Vc2sf6D0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "POSITIVE_SCORE=[]\n",
        "NEGATIVE_SCORE=[]\n",
        "POLARITY_SCORE=[]\n",
        "SUBJECTIVITY_SCORE=[]\n",
        "AVG_SENTENCE_LENGTH=[]\n",
        "PERCENTAGE_OF_COMPLEX_WORDS=[]\n",
        "FOG_INDEX=[]\n",
        "AVG_NUMBER_OF_WORDS_PER_SENTENCE=[]\n",
        "COMPLEX_WORD_COUNT=[]\n",
        "WORD_COUNT=[]\n",
        "SYLLABLE_PER_WORD=[]\n",
        "PERSONAL_PRONOUNS=[]\n",
        "AVG_WORD_LENGTH=[]\n"
      ],
      "metadata": {
        "id": "lstp-AhZf5su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_score=0\n",
        "negative_score=0\n",
        "polarity_score=0\n",
        "subjectivity_score=0\n",
        "average_sentence_length=0\n",
        "percentage_of_complex_words=0\n",
        "fog_index=0\n",
        "average_number_of_words_per_sentence=0\n",
        "complex_word_count=0\n",
        "word_count=0\n",
        "syllable_per_word=0\n",
        "personal_pronouns=0\n",
        "average_word_length=0"
      ],
      "metadata": {
        "id": "hoA_scsyIY58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "def subj_score(input):\n",
        " sia=SentimentIntensityAnalyzer()\n",
        " scores=sia.polarity_scores(\" \".join(input))\n",
        " subjectivity_score = scores['compound']\n",
        " return subj_score"
      ],
      "metadata": {
        "id": "YZgCH54InJT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#percentage_of_complex_words\n",
        "import nltk"
      ],
      "metadata": {
        "id": "NI-HU-2isjJN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining function to calculate  complex words\n",
        "def complex_num(text):\n",
        "  word_list=nltk.word_tokenize(\" \".join(text))\n",
        "  for word in word_list:\n",
        "    syllables=cmudict.get(word.lower())\n",
        "    if syllables:\n",
        "            num_syllables = len(list(filter(lambda s: s[-1].isdigit(), syllables[0])))\n",
        "    else:\n",
        "            num_syllables = 0\n",
        "    if num_syllables >= 3:\n",
        "            complex_count += 1\n",
        "    total_count += 1\n",
        "  return  (complex_count / total_count) * 100,complex_count"
      ],
      "metadata": {
        "id": "yF_A9RtS9z-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_syllables_per_word(text):\n",
        "    cmudict = nltk.corpus.cmudict.dict()\n",
        "    total_syllables = 0\n",
        "    total_words = 0\n",
        "    for word in words_list:\n",
        "        syllables = cmudict.get(word.lower())\n",
        "        if syllables:\n",
        "            num_syllables = len(list(filter(lambda s: s[-1].isdigit(), syllables[0])))\n",
        "        else:\n",
        "            num_syllables = 0\n",
        "        total_syllables += num_syllables\n",
        "        total_words += 1\n",
        "    return total_syllables / total_words\n"
      ],
      "metadata": {
        "id": "owcIyNh9DXNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_words=0\n",
        "len_line=0\n",
        "words_list=nltk.word_tokenize(\" \".join(main_text))\n",
        "for word in words_list:\n",
        "    len_line+=len(word)\n",
        "    if word.lower() in positive:\n",
        "      positive_score+=1\n",
        "    if word.lower() in negative:\n",
        "      negative_score+=1\n",
        "    if word.lower() in personal_pronouns:\n",
        "      personal_pronouns+=1\n",
        "polarity_score=(polarity_score-negative_score)/len(words_list)\n",
        "subjectivity_score=subj_score(main_text)\n",
        "average_sentence_length=len_line/len(main_text)\n",
        "percentage_of_complex_words,complex_word_count=complex_num(main_text)\n",
        "fog_index=(len(words_list/len(main_text))+100*percentage_of_complex_words)*0.4\n",
        "average_number_of_words_per_sentence=len(words_list)/len(main_text)\n",
        "#complex_word_count=\n",
        "word_count=len(words_list)\n",
        "syllable_per_word=calculate_syllables_per_word(words_list)\n",
        "#personal_pronouns=\n",
        "average_word_length=len_line/len(words_list)\n",
        "#append values to  list\n",
        "POSITIVE_SCORE.append(positive)\n",
        "NEGATIVE_SCORE.append(negative)\n",
        "POLARITY_SCORE.append(polarity_score)\n",
        "SUBJECTIVITY_SCORE.append(polarity_score)\n",
        "AVG_SENTENCE_LENGTH.append(average_sentence_length)\n",
        "PERCENTAGE_OF_COMPLEX_WORDS.append(percentage_of_complex_words)\n",
        "FOG_INDEX.append(fog_index)\n",
        "AVG_NUMBER_OF_WORDS_PER_SENTENCE.append(average_number_of_words_per_sentence)\n",
        "COMPLEX_WORD_COUNT.append(complex_word_count)\n",
        "WORD_COUNT.append(word_count)\n",
        "SYLLABLE_PER_WORD.append(syllable_per_word)\n",
        "PERSONAL_PRONOUNS.append(personal_pronouns)\n",
        "AVG_WORD_LENGTH.append(average_word_length)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yZUO9yDTIFzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IuZK9zptnFOn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}