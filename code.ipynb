{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef5LrCSCyHQt"
      },
      "source": [
        "###Data Extraction and NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {
        "id": "Bxv8si8Wx7Y1"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI-HU-2isjJN",
        "outputId": "7ade44fb-ba08-4dd3-a5b5-b6773b1259ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package cmudict to\n",
            "[nltk_data]     C:\\Users\\prabh\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 311,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('cmudict')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6_ktcVqIWSa",
        "outputId": "fa1cb750-4bfd-46b8-ad3f-f667f269c970"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\prabh\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\prabh\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 312,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "id": "QJdspAAmGoyx"
      },
      "outputs": [],
      "source": [
        "positive_fname='D:/blackcoffer/positive-words.txt' #file path of positive word list txt\n",
        "negative_fname='D:/blackcoffer/negative-words.txt'  #file path of negetive word list txt\n",
        "stopword1_fname='D:/blackcoffer/StopWords_Generic.txt' #file path of stopword word list txt\n",
        "input_fname='D:/blackcoffer/Input.xlsx - Sheet1.csv'   #input file path .csv file\n",
        "stopword2_fname='D:/blackcoffer/StopWords_GenericLong.txt' #file path of stopword word list txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "id": "7m244YhcEB54"
      },
      "outputs": [],
      "source": [
        "#list  of pronouns used taken from internet\n",
        "pronouns = ['i', 'me', 'my', 'mine', 'you', 'your', 'yours', 'he', 'him', 'his', 'she', 'her', 'hers', 'it', 'its', 'we', 'us', 'our', 'ours', 'they', 'them', 'their', 'theirs']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "id": "cS1D4pPjGy6_"
      },
      "outputs": [],
      "source": [
        "from os import remove\n",
        "positive=[]\n",
        " # Declaring positive words list\n",
        "negative=[] \n",
        "# Declaring negative words list\n",
        "stopword=[]\n",
        " # Declaring stopwords words list\n",
        "\n",
        "with open(positive_fname,mode='r') as file:\n",
        "  positive_words=file.readlines() #opening txt file\n",
        "\n",
        "for word in positive_words:            #adding files to list\n",
        "  positive.append(word[:len(word)-1])\n",
        "\n",
        "with open(negative_fname,mode='r',encoding='ISO-8859-1') as file:\n",
        "  negative_words=file.readlines()\n",
        "\n",
        "for word in negative_words:\n",
        "  negative.append(word[:len(word)-1])     #adding files to list\n",
        "#opening stop words \n",
        "with open(stopword1_fname,mode='r',encoding='ISO-8859-1') as file1,open(stopword2_fname,mode='r',encoding='ISO-8859-1')as file2:\n",
        "  stopword_words=file1.readlines()\n",
        "  stopword_words2=file2.readlines()\n",
        "for word in stopword_words+stopword_words2:\n",
        "  stopword.append(word[:len(word)-1])     #adding files to list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {},
      "outputs": [],
      "source": [
        "#removing pronouns from stopwords\n",
        "#we need the count of pronouns from article \n",
        "for i in pronouns:\n",
        "    if i in stopword: \n",
        "        stopword.remove(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize    \n",
        "import nltk  #nltk "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_df=pd.read_csv(input_fname) #reading csv Dataframe input_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {},
      "outputs": [],
      "source": [
        "#list to remove unwanted lines from article. repeating sendences\n",
        "waste=[\"Output exceeds the size limit. Open the full output data in a text editor1\",\"Introduction\",\"Contact us: hello@blackcoffer.com\",\"Â© All Right Reserved, Blackcoffer(OPC) Pvt. Ltd\",\"Ranking customer behaviours for business strategy\",\"Algorithmic trading for multiple commodities markets, like Forex, Metals, Energy, etc.\",\"Trading Bot for FOREX\",\"Python model for the analysis of sector-specific stock ETFs for investment purposes\",\"Playstore & Appstore to Google Analytics (GA) or Firebase to Google Data Studio Mobile App KPI Dashboard\",\"Google Local Service Ads LSA API To Google BigQuery to Google Data Studio\",\"AI Conversational Bot using RASA\",\"Recommendation System Architecture\",\"Rise of telemedicine and its Impact on Livelihood by 2040\",\"Rise of e-health and its impact on humans by the year 2030\",\"Rise of e-health and its impact on humans by the year 2030\",\"Rise of telemedicine and its Impact on Livelihood by 2040\",\"AI/ML and Predictive Modeling\",\"Solution for Contact Centre Problems\",\"How to Setup Custom Domain for Google App Engine Application?\",\"Code Review Checklist\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Code to web scrap from given links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6dwBfYSzVPX",
        "outputId": "4acbf26d-3cd4-415c-9be7-4392803d0098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/114 of file completed\n",
            "2/114 of file completed\n",
            "3/114 of file completed\n",
            "4/114 of file completed\n",
            "5/114 of file completed\n",
            "6/114 of file completed\n",
            "7/114 of file completed\n",
            "8/114 of file completed\n",
            "9/114 of file completed\n",
            "10/114 of file completed\n",
            "11/114 of file completed\n",
            "12/114 of file completed\n",
            "13/114 of file completed\n",
            "14/114 of file completed\n",
            "15/114 of file completed\n",
            "16/114 of file completed\n",
            "17/114 of file completed\n",
            "18/114 of file completed\n",
            "19/114 of file completed\n",
            "20/114 of file completed\n",
            "21/114 of file completed\n",
            "22/114 of file completed\n",
            "23/114 of file completed\n",
            "24/114 of file completed\n",
            "25/114 of file completed\n",
            "26/114 of file completed\n",
            "27/114 of file completed\n",
            "28/114 of file completed\n",
            "29/114 of file completed\n",
            "30/114 of file completed\n",
            "31/114 of file completed\n",
            "32/114 of file completed\n",
            "33/114 of file completed\n",
            "34/114 of file completed\n",
            "35/114 of file completed\n",
            "36/114 of file completed\n",
            "37/114 of file completed\n",
            "38/114 of file completed\n",
            "39/114 of file completed\n",
            "40/114 of file completed\n",
            "41/114 of file completed\n",
            "42/114 of file completed\n",
            "43/114 of file completed\n",
            "44/114 of file completed\n",
            "45/114 of file completed\n",
            "46/114 of file completed\n",
            "47/114 of file completed\n",
            "48/114 of file completed\n",
            "49/114 of file completed\n",
            "50/114 of file completed\n",
            "51/114 of file completed\n",
            "52/114 of file completed\n",
            "53/114 of file completed\n",
            "54/114 of file completed\n",
            "55/114 of file completed\n",
            "56/114 of file completed\n",
            "57/114 of file completed\n",
            "58/114 of file completed\n",
            "59/114 of file completed\n",
            "60/114 of file completed\n",
            "61/114 of file completed\n",
            "62/114 of file completed\n",
            "63/114 of file completed\n",
            "64/114 of file completed\n",
            "65/114 of file completed\n",
            "66/114 of file completed\n",
            "67/114 of file completed\n",
            "68/114 of file completed\n",
            "69/114 of file completed\n",
            "70/114 of file completed\n",
            "71/114 of file completed\n",
            "72/114 of file completed\n",
            "73/114 of file completed\n",
            "74/114 of file completed\n",
            "75/114 of file completed\n",
            "76/114 of file completed\n",
            "77/114 of file completed\n",
            "78/114 of file completed\n",
            "79/114 of file completed\n",
            "80/114 of file completed\n",
            "81/114 of file completed\n",
            "82/114 of file completed\n",
            "83/114 of file completed\n",
            "84/114 of file completed\n",
            "85/114 of file completed\n",
            "86/114 of file completed\n",
            "87/114 of file completed\n",
            "88/114 of file completed\n",
            "89/114 of file completed\n",
            "90/114 of file completed\n",
            "91/114 of file completed\n",
            "92/114 of file completed\n",
            "93/114 of file completed\n",
            "94/114 of file completed\n",
            "95/114 of file completed\n",
            "96/114 of file completed\n",
            "97/114 of file completed\n",
            "98/114 of file completed\n",
            "99/114 of file completed\n",
            "100/114 of file completed\n",
            "101/114 of file completed\n",
            "102/114 of file completed\n",
            "103/114 of file completed\n",
            "104/114 of file completed\n",
            "105/114 of file completed\n",
            "106/114 of file completed\n",
            "107/114 of file completed\n",
            "108/114 of file completed\n",
            "109/114 of file completed\n",
            "110/114 of file completed\n",
            "111/114 of file completed\n",
            "112/114 of file completed\n",
            "113/114 of file completed\n",
            "114/114 of file completed\n"
          ]
        }
      ],
      "source": [
        "from pandas.io.formats.format import format_array\n",
        "i=0\n",
        "main_text=[]  # declating main list to add up all article\n",
        "for url in input_df['URL']: # to loop through all links in input\n",
        " i+=1                          # To know which linkis currently scrapping\n",
        " text=\"\"                    # declaring text to nill\n",
        " response=requests.get(url)\n",
        " soup=BeautifulSoup(response.content,'html.parser')\n",
        " main_div=soup.find_all('div',{ 'class':\"tdb-block-inner td-fix-index\"})\n",
        " text2=soup.find_all('p')  #to find all p tag\n",
        " print(\"{}/{} of file completed\".format(i,len(input_df))) \n",
        " for div in text2:\n",
        "   if div.text not in waste:\n",
        "    text=text+div.text     #add all lines of  article to one into one string\n",
        " main_text.append([text])       # Append text to main_rext\n",
        "#print(main_text)     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "114"
            ]
          },
          "execution_count": 321,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(main_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#importing countVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {},
      "outputs": [],
      "source": [
        "#creating object of count vectoriser\n",
        "vectoriser=CountVectorizer(lowercase=True,tokenizer=word_tokenize,stop_words=stopword,max_features=12440)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {},
      "outputs": [],
      "source": [
        "#making it into list of string\n",
        "input_words=[]\n",
        "for article in main_text:\n",
        "    input_words.append(article[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\prabh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "C:\\Users\\prabh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", 'ai', 'ca', 'he', 'her', 'hers', 'him', 'his', 'i', 'it', 'its', 'me', 'my', \"n't\", 'our', 'ours', 'she', 'their', 'theirs', 'them', 'they', 'we', 'wo', 'you', 'your', 'yours', 'yourselve'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(max_features=12440,\n",
              "                stop_words=[&#x27;ABOUT&#x27;, &#x27;ABOVE&#x27;, &#x27;AFTER&#x27;, &#x27;AGAIN&#x27;, &#x27;ALL&#x27;, &#x27;AM&#x27;,\n",
              "                            &#x27;AMONG&#x27;, &#x27;AN&#x27;, &#x27;AND&#x27;, &#x27;ANY&#x27;, &#x27;ARE&#x27;, &#x27;AS&#x27;, &#x27;AT&#x27;,\n",
              "                            &#x27;BE&#x27;, &#x27;BECAUSE&#x27;, &#x27;BEEN&#x27;, &#x27;BEFORE&#x27;, &#x27;BEING&#x27;, &#x27;BELOW&#x27;,\n",
              "                            &#x27;BETWEEN&#x27;, &#x27;BOTH&#x27;, &#x27;BUT&#x27;, &#x27;BY&#x27;, &#x27;CAN&#x27;, &#x27;DID&#x27;, &#x27;DO&#x27;,\n",
              "                            &#x27;DOES&#x27;, &#x27;DOING&#x27;, &#x27;DOWN&#x27;, &#x27;DURING&#x27;, ...],\n",
              "                tokenizer=&lt;function word_tokenize at 0x0000022C124BA200&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_features=12440,\n",
              "                stop_words=[&#x27;ABOUT&#x27;, &#x27;ABOVE&#x27;, &#x27;AFTER&#x27;, &#x27;AGAIN&#x27;, &#x27;ALL&#x27;, &#x27;AM&#x27;,\n",
              "                            &#x27;AMONG&#x27;, &#x27;AN&#x27;, &#x27;AND&#x27;, &#x27;ANY&#x27;, &#x27;ARE&#x27;, &#x27;AS&#x27;, &#x27;AT&#x27;,\n",
              "                            &#x27;BE&#x27;, &#x27;BECAUSE&#x27;, &#x27;BEEN&#x27;, &#x27;BEFORE&#x27;, &#x27;BEING&#x27;, &#x27;BELOW&#x27;,\n",
              "                            &#x27;BETWEEN&#x27;, &#x27;BOTH&#x27;, &#x27;BUT&#x27;, &#x27;BY&#x27;, &#x27;CAN&#x27;, &#x27;DID&#x27;, &#x27;DO&#x27;,\n",
              "                            &#x27;DOES&#x27;, &#x27;DOING&#x27;, &#x27;DOWN&#x27;, &#x27;DURING&#x27;, ...],\n",
              "                tokenizer=&lt;function word_tokenize at 0x0000022C124BA200&gt;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "CountVectorizer(max_features=12440,\n",
              "                stop_words=['ABOUT', 'ABOVE', 'AFTER', 'AGAIN', 'ALL', 'AM',\n",
              "                            'AMONG', 'AN', 'AND', 'ANY', 'ARE', 'AS', 'AT',\n",
              "                            'BE', 'BECAUSE', 'BEEN', 'BEFORE', 'BEING', 'BELOW',\n",
              "                            'BETWEEN', 'BOTH', 'BUT', 'BY', 'CAN', 'DID', 'DO',\n",
              "                            'DOES', 'DOING', 'DOWN', 'DURING', ...],\n",
              "                tokenizer=<function word_tokenize at 0x0000022C124BA200>)"
            ]
          },
          "execution_count": 325,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectoriser.fit(input_words) #creating words list bag of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {},
      "outputs": [],
      "source": [
        "input=vectoriser.fit_transform(input_words)  #transforming atricle into bag of method vector form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['!', '#', '$', ..., 'â¹4,200', 'â¹419', 'â¹59'], dtype=object)"
            ]
          },
          "execution_count": 327,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectoriser.get_feature_names_out() #to get list of words in bag of method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {},
      "outputs": [],
      "source": [
        "# url='https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/' \n",
        "# response=requests.get(url)\n",
        "# soup=BeautifulSoup(response.content,'html.parser')\n",
        "# main_div=soup.find_all('div',{ 'class':\"tdb-block-inner td-fix-index\"})    #train code\n",
        "# text2=soup.find_all('p')\n",
        "# sec_text=[]\n",
        "# print(i)\n",
        "# for div in text2:\n",
        "#    if div.text not in waste:\n",
        "#     text.append(div.text)\n",
        "# print(text) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {},
      "outputs": [],
      "source": [
        "#saved all unique words to unique_words\n",
        "unique_words=vectoriser.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {},
      "outputs": [],
      "source": [
        "#assigning everything with zero\n",
        "POSITIVE_SCORE=0 #\n",
        "NEGATIVE_SCORE=0 #\n",
        "POLARITY_SCORE=0 #\n",
        "SUBJECTIVITY_SCORE=0 #\n",
        "AVG_SENTENCE_LENGTH=0#\n",
        "PERCENTAGE_OF_COMPLEX_WORDS=0 #\n",
        "FOG_INDEX=0 #\n",
        "AVG_NUMBER_OF_WORDS_PER_SENTENCE=0 #\n",
        "COMPLEX_WORD_COUNT=0 #\n",
        "WORD_COUNT=0 #\n",
        "SYLLABLE_PER_WORD=0 #\n",
        "PERSONAL_PRONOUNS=0 #\n",
        "AVG_WORD_LENGTH=0 #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {},
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "def is_complex(word):\n",
        "    # Strip any punctuation from the word\n",
        "    word = word.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Count the number of vowels in the word\n",
        "    num_vowels = len(re.findall(r'[aeiouy]+', word, re.IGNORECASE))\n",
        "\n",
        "    # Count the number of syllables based on the number of vowels\n",
        "    num_syllables = max(1, num_vowels - 1)\n",
        "\n",
        "    # Determine whether the word is complex based on its number of syllables\n",
        "    if num_syllables >= 3:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {},
      "outputs": [],
      "source": [
        "def syll(word):\n",
        " i=0\n",
        " for char in word:\n",
        "    if char in ['a,','e','i','o','u']:\n",
        "      i+=1\n",
        " return i          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 333,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input.toarray()[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_array=input.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 3, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 335,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {},
      "outputs": [],
      "source": [
        "output=[]\n",
        "for value in input.toarray():\n",
        "    syll_value = 0\n",
        "    word_len = 0\n",
        "    no_complex = 0\n",
        "    POSITIVE_SCORE = 0\n",
        "    NEGATIVE_SCORE = 0\n",
        "    PERSONAL_PRONOUNS = 0\n",
        "    sum_value_second = sum(value)\n",
        "    \n",
        "    for i, value_second in enumerate(value):\n",
        "        if value_second > 0:\n",
        "            vector_index = i\n",
        "            value = unique_words[vector_index]\n",
        "            syll_value += syll(value)\n",
        "            word_len += len(value)\n",
        "            if value in pronouns:      \n",
        "                 PERSONAL_PRONOUNS+= 1\n",
        "            if syll_value >= 3:\n",
        "                if is_complex(value):\n",
        "                    no_complex += 1\n",
        "                \n",
        "            if value in positive:\n",
        "                POSITIVE_SCORE += value_second\n",
        "            elif value in negative:\n",
        "                NEGATIVE_SCORE += value_second\n",
        "            \n",
        "                \n",
        "    POLARITY_SCORE = ((POSITIVE_SCORE - NEGATIVE_SCORE) / (POSITIVE_SCORE + NEGATIVE_SCORE + 0.000001))\n",
        "    SUBJECTIVITY_SCORE = ((POSITIVE_SCORE + NEGATIVE_SCORE) / (sum_value_second + 0.000001))\n",
        "    dot_index = vectoriser.vocabulary_.get(\".\")\n",
        "    AVG_SENTENCE_LENGTH = sum_value_second / (input[:, dot_index].sum() + 0.000001)\n",
        "    PERCENTAGE_OF_COMPLEX_WORDS = no_complex / (sum_value_second + 0.000001)\n",
        "    FOG_INDEX = 0.4 * ((AVG_SENTENCE_LENGTH) + (PERCENTAGE_OF_COMPLEX_WORDS * 100))\n",
        "    AVG_NUMBER_OF_WORDS_PER_SENTENCE = sum_value_second / (input[:, dot_index].sum() + 0.000001)\n",
        "    COMPLEX_WORD_COUNT = no_complex\n",
        "    WORD_COUNT = sum_value_second\n",
        "    SYLLABLE_PER_WORD = syll_value / (sum_value_second + 0.000001)\n",
        "    AVG_WORD_LENGTH = word_len / (sum_value_second + 0.000001)\n",
        "    output.append([POSITIVE_SCORE,NEGATIVE_SCORE,POLARITY_SCORE,SUBJECTIVITY_SCORE,AVG_SENTENCE_LENGTH,PERCENTAGE_OF_COMPLEX_WORDS,FOG_INDEX,AVG_NUMBER_OF_WORDS_PER_SENTENCE,COMPLEX_WORD_COUNT,WORD_COUNT,SYLLABLE_PER_WORD,PERSONAL_PRONOUNS,AVG_WORD_LENGTH])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_list=input_df.values.tolist() #converting input dataframe to list "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_list_df=pd.DataFrame(input_list,columns=[\"URL_ID\",\"URL\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[37,\n",
              "  'https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/'],\n",
              " [38,\n",
              "  'https://insights.blackcoffer.com/what-if-the-creation-is-taking-over-the-creator/'],\n",
              " [39,\n",
              "  'https://insights.blackcoffer.com/what-jobs-will-robots-take-from-humans-in-the-future/'],\n",
              " [40,\n",
              "  'https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/'],\n",
              " [41, 'https://insights.blackcoffer.com/will-ai-replace-us-or-work-with-us/'],\n",
              " [42,\n",
              "  'https://insights.blackcoffer.com/man-and-machines-together-machines-are-more-diligent-than-humans-blackcoffe/'],\n",
              " [43,\n",
              "  'https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/'],\n",
              " [44,\n",
              "  'https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/'],\n",
              " [45,\n",
              "  'https://insights.blackcoffer.com/how-machine-learning-will-affect-your-business/'],\n",
              " [46,\n",
              "  'https://insights.blackcoffer.com/deep-learning-impact-on-areas-of-e-learning/'],\n",
              " [47,\n",
              "  'https://insights.blackcoffer.com/how-to-protect-future-data-and-its-privacy-blackcoffer/'],\n",
              " [48,\n",
              "  'https://insights.blackcoffer.com/how-machines-ai-automations-and-robo-human-are-effective-in-finance-and-banking/'],\n",
              " [49,\n",
              "  'https://insights.blackcoffer.com/ai-human-robotics-machine-future-planet-blackcoffer-thinking-jobs-workplace/'],\n",
              " [50,\n",
              "  'https://insights.blackcoffer.com/how-ai-will-change-the-world-blackcoffer/'],\n",
              " [51,\n",
              "  'https://insights.blackcoffer.com/future-of-work-how-ai-has-entered-the-workplace/'],\n",
              " [52,\n",
              "  'https://insights.blackcoffer.com/ai-tool-alexa-google-assistant-finance-banking-tool-future/'],\n",
              " [53,\n",
              "  'https://insights.blackcoffer.com/ai-healthcare-revolution-ml-technology-algorithm-google-analytics-industrialrevolution/'],\n",
              " [54,\n",
              "  'https://insights.blackcoffer.com/all-you-need-to-know-about-online-marketing/'],\n",
              " [55, 'https://insights.blackcoffer.com/evolution-of-advertising-industry/'],\n",
              " [56,\n",
              "  'https://insights.blackcoffer.com/how-data-analytics-can-help-your-business-respond-to-the-impact-of-covid-19/'],\n",
              " [57,\n",
              "  'https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/'],\n",
              " [58,\n",
              "  'https://insights.blackcoffer.com/environmental-impact-of-the-covid-19-pandemic-lesson-for-the-future/'],\n",
              " [59,\n",
              "  'https://insights.blackcoffer.com/how-data-analytics-and-ai-are-used-to-halt-the-covid-19-pandemic/'],\n",
              " [60,\n",
              "  'https://insights.blackcoffer.com/difference-between-artificial-intelligence-machine-learning-statistics-and-data-mining/'],\n",
              " [61,\n",
              "  'https://insights.blackcoffer.com/how-python-became-the-first-choice-for-data-science/'],\n",
              " [62,\n",
              "  'https://insights.blackcoffer.com/how-google-fit-measure-heart-and-respiratory-rates-using-a-phone/'],\n",
              " [63, 'https://insights.blackcoffer.com/what-is-the-future-of-mobile-apps/'],\n",
              " [64, 'https://insights.blackcoffer.com/impact-of-ai-in-health-and-medicine/'],\n",
              " [65,\n",
              "  'https://insights.blackcoffer.com/telemedicine-what-patients-like-and-dislike-about-it/'],\n",
              " [66, 'https://insights.blackcoffer.com/how-we-forecast-future-technologies/'],\n",
              " [67,\n",
              "  'https://insights.blackcoffer.com/can-robots-tackle-late-life-loneliness/'],\n",
              " [68,\n",
              "  'https://insights.blackcoffer.com/embedding-care-robots-into-society-socio-technical-considerations/'],\n",
              " [69,\n",
              "  'https://insights.blackcoffer.com/management-challenges-for-future-digitalization-of-healthcare-services/'],\n",
              " [70,\n",
              "  'https://insights.blackcoffer.com/are-we-any-closer-to-preventing-a-nuclear-holocaust/'],\n",
              " [71,\n",
              "  'https://insights.blackcoffer.com/will-technology-eliminate-the-need-for-animal-testing-in-drug-development/'],\n",
              " [72,\n",
              "  'https://insights.blackcoffer.com/will-we-ever-understand-the-nature-of-consciousness/'],\n",
              " [73, 'https://insights.blackcoffer.com/will-we-ever-colonize-outer-space/'],\n",
              " [74,\n",
              "  'https://insights.blackcoffer.com/what-is-the-chance-homo-sapiens-will-survive-for-the-next-500-years/'],\n",
              " [75,\n",
              "  'https://insights.blackcoffer.com/why-does-your-business-need-a-chatbot/'],\n",
              " [76,\n",
              "  'https://insights.blackcoffer.com/how-you-lead-a-project-or-a-team-without-any-technical-expertise/'],\n",
              " [77,\n",
              "  'https://insights.blackcoffer.com/can-you-be-great-leader-without-technical-expertise/'],\n",
              " [78,\n",
              "  'https://insights.blackcoffer.com/how-does-artificial-intelligence-affect-the-environment/'],\n",
              " [79,\n",
              "  'https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes-2/'],\n",
              " [80,\n",
              "  'https://insights.blackcoffer.com/is-perfection-the-greatest-enemy-of-productivity/'],\n",
              " [81,\n",
              "  'https://insights.blackcoffer.com/global-financial-crisis-2008-causes-effects-and-its-solution/'],\n",
              " [82,\n",
              "  'https://insights.blackcoffer.com/gender-diversity-and-equality-in-the-tech-industry/'],\n",
              " [83,\n",
              "  'https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes/'],\n",
              " [84,\n",
              "  'https://insights.blackcoffer.com/how-small-business-can-survive-the-coronavirus-crisis/'],\n",
              " [85,\n",
              "  'https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors-and-food-stalls/'],\n",
              " [86,\n",
              "  'https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors/'],\n",
              " [87,\n",
              "  'https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-tourism-aviation-industries/'],\n",
              " [88,\n",
              "  'https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-sports-events-around-the-world/'],\n",
              " [89,\n",
              "  'https://insights.blackcoffer.com/changing-landscape-and-emerging-trends-in-the-indian-it-ites-industry/'],\n",
              " [90,\n",
              "  'https://insights.blackcoffer.com/online-gaming-adolescent-online-gaming-effects-demotivated-depression-musculoskeletal-and-psychosomatic-symptoms/'],\n",
              " [91, 'https://insights.blackcoffer.com/human-rights-outlook/'],\n",
              " [92,\n",
              "  'https://insights.blackcoffer.com/how-voice-search-makes-your-business-a-successful-business/'],\n",
              " [93,\n",
              "  'https://insights.blackcoffer.com/how-the-covid-19-crisis-is-redefining-jobs-and-services/'],\n",
              " [94,\n",
              "  'https://insights.blackcoffer.com/how-to-increase-social-media-engagement-for-marketers/'],\n",
              " [95,\n",
              "  'https://insights.blackcoffer.com/impacts-of-covid-19-on-streets-sides-food-stalls/'],\n",
              " [96,\n",
              "  'https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets-2/'],\n",
              " [97,\n",
              "  'https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-5/'],\n",
              " [98,\n",
              "  'https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-4/'],\n",
              " [99,\n",
              "  'https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-2/'],\n",
              " [100,\n",
              "  'https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-3/'],\n",
              " [101, 'https://insights.blackcoffer.com/travel-and-tourism-outlook/'],\n",
              " [102,\n",
              "  'https://insights.blackcoffer.com/gaming-disorder-and-effects-of-gaming-on-health/'],\n",
              " [103,\n",
              "  'https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation/'],\n",
              " [104,\n",
              "  'https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation-2/'],\n",
              " [105,\n",
              "  'https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-office-space-and-co-working-industries/'],\n",
              " [106,\n",
              "  'https://insights.blackcoffer.com/contribution-of-handicrafts-visual-arts-literature-in-the-indian-economy/'],\n",
              " [107,\n",
              "  'https://insights.blackcoffer.com/how-covid-19-is-impacting-payment-preferences/'],\n",
              " [108,\n",
              "  'https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-2/'],\n",
              " [109,\n",
              "  'https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis/'],\n",
              " [110,\n",
              "  'https://insights.blackcoffer.com/covid-19-how-have-countries-been-responding/'],\n",
              " [111,\n",
              "  'https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-2/'],\n",
              " [112,\n",
              "  'https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-3/'],\n",
              " [113,\n",
              "  'https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-3/'],\n",
              " [114,\n",
              "  'https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work/'],\n",
              " [115,\n",
              "  'https://insights.blackcoffer.com/covid-19-how-have-countries-been-responding-2/'],\n",
              " [116,\n",
              "  'https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-4/'],\n",
              " [117,\n",
              "  'https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-2/'],\n",
              " [118,\n",
              "  'https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-3/'],\n",
              " [119,\n",
              "  'https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-4/'],\n",
              " [120,\n",
              "  'https://insights.blackcoffer.com/why-scams-like-nirav-modi-happen-with-indian-banks/'],\n",
              " [121,\n",
              "  'https://insights.blackcoffer.com/impact-of-covid-19-on-the-global-economy/'],\n",
              " [122,\n",
              "  'https://insights.blackcoffer.com/impact-of-covid-19coronavirus-on-the-indian-economy-2/'],\n",
              " [123,\n",
              "  'https://insights.blackcoffer.com/impact-of-covid-19-on-the-global-economy-2/'],\n",
              " [124,\n",
              "  'https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-indian-economy-3/'],\n",
              " [125,\n",
              "  'https://insights.blackcoffer.com/should-celebrities-be-allowed-to-join-politics/'],\n",
              " [126,\n",
              "  'https://insights.blackcoffer.com/how-prepared-is-india-to-tackle-a-possible-covid-19-outbreak/'],\n",
              " [127,\n",
              "  'https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work/'],\n",
              " [128,\n",
              "  'https://insights.blackcoffer.com/controversy-as-a-marketing-strategy/'],\n",
              " [129,\n",
              "  'https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry/'],\n",
              " [130,\n",
              "  'https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets/'],\n",
              " [131,\n",
              "  'https://insights.blackcoffer.com/what-are-the-key-policies-that-will-mitigate-the-impacts-of-covid-19-on-the-world-of-work/'],\n",
              " [132,\n",
              "  'https://insights.blackcoffer.com/marketing-drives-results-with-a-focus-on-problems/'],\n",
              " [133,\n",
              "  'https://insights.blackcoffer.com/continued-demand-for-sustainability/'],\n",
              " [134,\n",
              "  'https://insights.blackcoffer.com/coronavirus-disease-covid-19-effect-the-impact-and-role-of-mass-media-during-the-pandemic/'],\n",
              " [135,\n",
              "  'https://insights.blackcoffer.com/should-people-wear-fabric-gloves-seeking-evidence-regarding-the-differential-transfer-of-covid-19-or-coronaviruses-generally-between-surfaces/'],\n",
              " [136,\n",
              "  'https://insights.blackcoffer.com/why-is-there-a-severe-immunological-and-inflammatory-explosion-in-those-affected-by-sarms-covid-19/'],\n",
              " [137,\n",
              "  'https://insights.blackcoffer.com/what-do-you-think-is-the-lesson-or-lessons-to-be-learned-with-covid-19/'],\n",
              " [138,\n",
              "  'https://insights.blackcoffer.com/coronavirus-the-unexpected-challenge-for-the-european-union/'],\n",
              " [139,\n",
              "  'https://insights.blackcoffer.com/industrial-revolution-4-0-pros-and-cons/'],\n",
              " [140,\n",
              "  'https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-indian-economy/'],\n",
              " [141,\n",
              "  'https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-indian-economy-2/'],\n",
              " [142,\n",
              "  'https://insights.blackcoffer.com/impact-of-covid-19coronavirus-on-the-indian-economy/'],\n",
              " [143,\n",
              "  'https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-global-economy/'],\n",
              " [144,\n",
              "  'https://insights.blackcoffer.com/ensuring-growth-through-insurance-technology/'],\n",
              " [145, 'https://insights.blackcoffer.com/blockchain-in-fintech/'],\n",
              " [146, 'https://insights.blackcoffer.com/blockchain-for-payments/'],\n",
              " [147, 'https://insights.blackcoffer.com/the-future-of-investing/'],\n",
              " [148, 'https://insights.blackcoffer.com/big-data-analytics-in-healthcare/'],\n",
              " [149,\n",
              "  'https://insights.blackcoffer.com/business-analytics-in-the-healthcare-industry/'],\n",
              " [150,\n",
              "  'https://insights.blackcoffer.com/challenges-and-opportunities-of-big-data-in-healthcare/']]"
            ]
          },
          "execution_count": 339,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in  range(0,len(input_list)):\n",
        "    output[i]=input_list[i]+output[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {},
      "outputs": [],
      "source": [
        "#converting output to dataframre\n",
        "output_df=pd.DataFrame(output,columns=['Url_id','url','POSITIVE_SCORE','NEGATIVE_SCORE','POLARITY_SCORE','SUBJECTIVITY_SCORE','AVG_SENTENCE_LENGTH','PERCENTAGE_OF_COMPLEX_WORDS','FOG_INDEX','AVG_NUMBER_OF_WORDS_PER_SENTENCE','COMPLEX_WORD_COUNT','WORD_COUNT','SYLLABLE_PER_WORD','PERSONAL_PRONOUNS','AVG_WORD_LENGTH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Url_id</th>\n",
              "      <th>url</th>\n",
              "      <th>POSITIVE_SCORE</th>\n",
              "      <th>NEGATIVE_SCORE</th>\n",
              "      <th>POLARITY_SCORE</th>\n",
              "      <th>SUBJECTIVITY_SCORE</th>\n",
              "      <th>AVG_SENTENCE_LENGTH</th>\n",
              "      <th>PERCENTAGE_OF_COMPLEX_WORDS</th>\n",
              "      <th>FOG_INDEX</th>\n",
              "      <th>AVG_NUMBER_OF_WORDS_PER_SENTENCE</th>\n",
              "      <th>COMPLEX_WORD_COUNT</th>\n",
              "      <th>WORD_COUNT</th>\n",
              "      <th>SYLLABLE_PER_WORD</th>\n",
              "      <th>PERSONAL_PRONOUNS</th>\n",
              "      <th>AVG_WORD_LENGTH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37</td>\n",
              "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
              "      <td>67</td>\n",
              "      <td>31</td>\n",
              "      <td>0.367347</td>\n",
              "      <td>0.078400</td>\n",
              "      <td>0.312578</td>\n",
              "      <td>0.137600</td>\n",
              "      <td>5.629031</td>\n",
              "      <td>0.312578</td>\n",
              "      <td>172</td>\n",
              "      <td>1250</td>\n",
              "      <td>1.346400</td>\n",
              "      <td>6</td>\n",
              "      <td>4.425600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38</td>\n",
              "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
              "      <td>60</td>\n",
              "      <td>36</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.105960</td>\n",
              "      <td>0.226557</td>\n",
              "      <td>0.096026</td>\n",
              "      <td>3.931682</td>\n",
              "      <td>0.226557</td>\n",
              "      <td>87</td>\n",
              "      <td>906</td>\n",
              "      <td>1.047461</td>\n",
              "      <td>10</td>\n",
              "      <td>3.426049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>39</td>\n",
              "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
              "      <td>68</td>\n",
              "      <td>37</td>\n",
              "      <td>0.295238</td>\n",
              "      <td>0.094680</td>\n",
              "      <td>0.277319</td>\n",
              "      <td>0.132552</td>\n",
              "      <td>5.413002</td>\n",
              "      <td>0.277319</td>\n",
              "      <td>147</td>\n",
              "      <td>1109</td>\n",
              "      <td>1.243463</td>\n",
              "      <td>9</td>\n",
              "      <td>4.085663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
              "      <td>65</td>\n",
              "      <td>22</td>\n",
              "      <td>0.494253</td>\n",
              "      <td>0.093750</td>\n",
              "      <td>0.232058</td>\n",
              "      <td>0.105603</td>\n",
              "      <td>4.316961</td>\n",
              "      <td>0.232058</td>\n",
              "      <td>98</td>\n",
              "      <td>928</td>\n",
              "      <td>1.093750</td>\n",
              "      <td>10</td>\n",
              "      <td>3.713362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
              "      <td>59</td>\n",
              "      <td>23</td>\n",
              "      <td>0.439024</td>\n",
              "      <td>0.073807</td>\n",
              "      <td>0.277819</td>\n",
              "      <td>0.088209</td>\n",
              "      <td>3.639481</td>\n",
              "      <td>0.277819</td>\n",
              "      <td>98</td>\n",
              "      <td>1111</td>\n",
              "      <td>1.126013</td>\n",
              "      <td>11</td>\n",
              "      <td>3.867687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>146</td>\n",
              "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
              "      <td>24</td>\n",
              "      <td>27</td>\n",
              "      <td>-0.058824</td>\n",
              "      <td>0.087031</td>\n",
              "      <td>0.146537</td>\n",
              "      <td>0.153584</td>\n",
              "      <td>6.201959</td>\n",
              "      <td>0.146537</td>\n",
              "      <td>90</td>\n",
              "      <td>586</td>\n",
              "      <td>1.486348</td>\n",
              "      <td>11</td>\n",
              "      <td>5.276451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>147</td>\n",
              "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
              "      <td>38</td>\n",
              "      <td>12</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.067024</td>\n",
              "      <td>0.186547</td>\n",
              "      <td>0.117962</td>\n",
              "      <td>4.793117</td>\n",
              "      <td>0.186547</td>\n",
              "      <td>88</td>\n",
              "      <td>746</td>\n",
              "      <td>1.215818</td>\n",
              "      <td>6</td>\n",
              "      <td>4.045576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>148</td>\n",
              "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
              "      <td>29</td>\n",
              "      <td>46</td>\n",
              "      <td>-0.226667</td>\n",
              "      <td>0.099469</td>\n",
              "      <td>0.188547</td>\n",
              "      <td>0.100796</td>\n",
              "      <td>4.107249</td>\n",
              "      <td>0.188547</td>\n",
              "      <td>76</td>\n",
              "      <td>754</td>\n",
              "      <td>1.022546</td>\n",
              "      <td>5</td>\n",
              "      <td>3.480106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>149</td>\n",
              "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
              "      <td>32</td>\n",
              "      <td>3</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.094086</td>\n",
              "      <td>0.093023</td>\n",
              "      <td>0.155914</td>\n",
              "      <td>6.273768</td>\n",
              "      <td>0.093023</td>\n",
              "      <td>58</td>\n",
              "      <td>372</td>\n",
              "      <td>1.478495</td>\n",
              "      <td>6</td>\n",
              "      <td>5.069892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>150</td>\n",
              "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
              "      <td>36</td>\n",
              "      <td>41</td>\n",
              "      <td>-0.064935</td>\n",
              "      <td>0.117199</td>\n",
              "      <td>0.164291</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>4.510161</td>\n",
              "      <td>0.164291</td>\n",
              "      <td>73</td>\n",
              "      <td>657</td>\n",
              "      <td>1.181126</td>\n",
              "      <td>8</td>\n",
              "      <td>3.809741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows Ã 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Url_id                                                url   \n",
              "0        37  https://insights.blackcoffer.com/ai-in-healthc...  \\\n",
              "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
              "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
              "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
              "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
              "..      ...                                                ...   \n",
              "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
              "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
              "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
              "112     149  https://insights.blackcoffer.com/business-anal...   \n",
              "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
              "\n",
              "     POSITIVE_SCORE  NEGATIVE_SCORE  POLARITY_SCORE  SUBJECTIVITY_SCORE   \n",
              "0                67              31        0.367347            0.078400  \\\n",
              "1                60              36        0.250000            0.105960   \n",
              "2                68              37        0.295238            0.094680   \n",
              "3                65              22        0.494253            0.093750   \n",
              "4                59              23        0.439024            0.073807   \n",
              "..              ...             ...             ...                 ...   \n",
              "109              24              27       -0.058824            0.087031   \n",
              "110              38              12        0.520000            0.067024   \n",
              "111              29              46       -0.226667            0.099469   \n",
              "112              32               3        0.828571            0.094086   \n",
              "113              36              41       -0.064935            0.117199   \n",
              "\n",
              "     AVG_SENTENCE_LENGTH  PERCENTAGE_OF_COMPLEX_WORDS  FOG_INDEX   \n",
              "0               0.312578                     0.137600   5.629031  \\\n",
              "1               0.226557                     0.096026   3.931682   \n",
              "2               0.277319                     0.132552   5.413002   \n",
              "3               0.232058                     0.105603   4.316961   \n",
              "4               0.277819                     0.088209   3.639481   \n",
              "..                   ...                          ...        ...   \n",
              "109             0.146537                     0.153584   6.201959   \n",
              "110             0.186547                     0.117962   4.793117   \n",
              "111             0.188547                     0.100796   4.107249   \n",
              "112             0.093023                     0.155914   6.273768   \n",
              "113             0.164291                     0.111111   4.510161   \n",
              "\n",
              "     AVG_NUMBER_OF_WORDS_PER_SENTENCE  COMPLEX_WORD_COUNT  WORD_COUNT   \n",
              "0                            0.312578                 172        1250  \\\n",
              "1                            0.226557                  87         906   \n",
              "2                            0.277319                 147        1109   \n",
              "3                            0.232058                  98         928   \n",
              "4                            0.277819                  98        1111   \n",
              "..                                ...                 ...         ...   \n",
              "109                          0.146537                  90         586   \n",
              "110                          0.186547                  88         746   \n",
              "111                          0.188547                  76         754   \n",
              "112                          0.093023                  58         372   \n",
              "113                          0.164291                  73         657   \n",
              "\n",
              "     SYLLABLE_PER_WORD  PERSONAL_PRONOUNS  AVG_WORD_LENGTH  \n",
              "0             1.346400                  6         4.425600  \n",
              "1             1.047461                 10         3.426049  \n",
              "2             1.243463                  9         4.085663  \n",
              "3             1.093750                 10         3.713362  \n",
              "4             1.126013                 11         3.867687  \n",
              "..                 ...                ...              ...  \n",
              "109           1.486348                 11         5.276451  \n",
              "110           1.215818                  6         4.045576  \n",
              "111           1.022546                  5         3.480106  \n",
              "112           1.478495                  6         5.069892  \n",
              "113           1.181126                  8         3.809741  \n",
              "\n",
              "[114 rows x 15 columns]"
            ]
          },
          "execution_count": 342,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_df #final output "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {},
      "outputs": [],
      "source": [
        "#converting output to csv\n",
        "output_df.to_csv('D:\\\\blackcoffer\\\\submission.csv',index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
